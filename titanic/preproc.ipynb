{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! = means that i did not fullly undrstand the concept"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   \n",
       "0              1         0       3  \\\n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp   \n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1  \\\n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file\n",
    "df = pd.read_csv('train.csv')\n",
    "df\n",
    "# note : you can use .head(default:5) or .tail(default:5) to see the first or last 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.  , 38.  , 26.  , 35.  , 35.  ,   nan, 54.  ,  2.  , 27.  ,\n",
       "       14.  ,  4.  , 58.  , 20.  , 39.  , 14.  , 55.  ,  2.  ,   nan,\n",
       "       31.  ,   nan, 35.  , 34.  , 15.  , 28.  ,  8.  , 38.  ,   nan,\n",
       "       19.  ,   nan,   nan, 40.  ,   nan,   nan, 66.  , 28.  , 42.  ,\n",
       "         nan, 21.  , 18.  , 14.  , 40.  , 27.  ,   nan,  3.  , 19.  ,\n",
       "         nan,   nan,   nan,   nan, 18.  ,  7.  , 21.  , 49.  , 29.  ,\n",
       "       65.  ,   nan, 21.  , 28.5 ,  5.  , 11.  , 22.  , 38.  , 45.  ,\n",
       "        4.  ,   nan,   nan, 29.  , 19.  , 17.  , 26.  , 32.  , 16.  ,\n",
       "       21.  , 26.  , 32.  , 25.  ,   nan,   nan,  0.83, 30.  , 22.  ,\n",
       "       29.  ,   nan, 28.  , 17.  , 33.  , 16.  ,   nan, 23.  , 24.  ,\n",
       "       29.  , 20.  , 46.  , 26.  , 59.  ,   nan, 71.  , 23.  , 34.  ,\n",
       "       34.  , 28.  ,   nan, 21.  , 33.  , 37.  , 28.  , 21.  ,   nan,\n",
       "       38.  ,   nan, 47.  , 14.5 , 22.  , 20.  , 17.  , 21.  , 70.5 ,\n",
       "       29.  , 24.  ,  2.  , 21.  ,   nan, 32.5 , 32.5 , 54.  , 12.  ,\n",
       "         nan, 24.  ,   nan, 45.  , 33.  , 20.  , 47.  , 29.  , 25.  ,\n",
       "       23.  , 19.  , 37.  , 16.  , 24.  ,   nan, 22.  , 24.  , 19.  ,\n",
       "       18.  , 19.  , 27.  ,  9.  , 36.5 , 42.  , 51.  , 22.  , 55.5 ,\n",
       "       40.5 ,   nan, 51.  , 16.  , 30.  ,   nan,   nan, 44.  , 40.  ,\n",
       "       26.  , 17.  ,  1.  ,  9.  ,   nan, 45.  ,   nan, 28.  , 61.  ,\n",
       "        4.  ,  1.  , 21.  , 56.  , 18.  ,   nan, 50.  , 30.  , 36.  ,\n",
       "         nan,   nan,  9.  ,  1.  ,  4.  ,   nan,   nan, 45.  , 40.  ,\n",
       "       36.  , 32.  , 19.  , 19.  ,  3.  , 44.  , 58.  ,   nan, 42.  ,\n",
       "         nan, 24.  , 28.  ,   nan, 34.  , 45.5 , 18.  ,  2.  , 32.  ,\n",
       "       26.  , 16.  , 40.  , 24.  , 35.  , 22.  , 30.  ,   nan, 31.  ,\n",
       "       27.  , 42.  , 32.  , 30.  , 16.  , 27.  , 51.  ,   nan, 38.  ,\n",
       "       22.  , 19.  , 20.5 , 18.  ,   nan, 35.  , 29.  , 59.  ,  5.  ,\n",
       "       24.  ,   nan, 44.  ,  8.  , 19.  , 33.  ,   nan,   nan, 29.  ,\n",
       "       22.  , 30.  , 44.  , 25.  , 24.  , 37.  , 54.  ,   nan, 29.  ,\n",
       "       62.  , 30.  , 41.  , 29.  ,   nan, 30.  , 35.  , 50.  ,   nan,\n",
       "        3.  , 52.  , 40.  ,   nan, 36.  , 16.  , 25.  , 58.  , 35.  ,\n",
       "         nan, 25.  , 41.  , 37.  ,   nan, 63.  , 45.  ,   nan,  7.  ,\n",
       "       35.  , 65.  , 28.  , 16.  , 19.  ,   nan, 33.  , 30.  , 22.  ,\n",
       "       42.  , 22.  , 26.  , 19.  , 36.  , 24.  , 24.  ,   nan, 23.5 ,\n",
       "        2.  ,   nan, 50.  ,   nan,   nan, 19.  ,   nan,   nan,  0.92,\n",
       "         nan, 17.  , 30.  , 30.  , 24.  , 18.  , 26.  , 28.  , 43.  ,\n",
       "       26.  , 24.  , 54.  , 31.  , 40.  , 22.  , 27.  , 30.  , 22.  ,\n",
       "         nan, 36.  , 61.  , 36.  , 31.  , 16.  ,   nan, 45.5 , 38.  ,\n",
       "       16.  ,   nan,   nan, 29.  , 41.  , 45.  , 45.  ,  2.  , 24.  ,\n",
       "       28.  , 25.  , 36.  , 24.  , 40.  ,   nan,  3.  , 42.  , 23.  ,\n",
       "         nan, 15.  , 25.  ,   nan, 28.  , 22.  , 38.  ,   nan,   nan,\n",
       "       40.  , 29.  , 45.  , 35.  ,   nan, 30.  , 60.  ,   nan,   nan,\n",
       "       24.  , 25.  , 18.  , 19.  , 22.  ,  3.  ,   nan, 22.  , 27.  ,\n",
       "       20.  , 19.  , 42.  ,  1.  , 32.  , 35.  ,   nan, 18.  ,  1.  ,\n",
       "       36.  ,   nan, 17.  , 36.  , 21.  , 28.  , 23.  , 24.  , 22.  ,\n",
       "       31.  , 46.  , 23.  , 28.  , 39.  , 26.  , 21.  , 28.  , 20.  ,\n",
       "       34.  , 51.  ,  3.  , 21.  ,   nan,   nan,   nan, 33.  ,   nan,\n",
       "       44.  ,   nan, 34.  , 18.  , 30.  , 10.  ,   nan, 21.  , 29.  ,\n",
       "       28.  , 18.  ,   nan, 28.  , 19.  ,   nan, 32.  , 28.  ,   nan,\n",
       "       42.  , 17.  , 50.  , 14.  , 21.  , 24.  , 64.  , 31.  , 45.  ,\n",
       "       20.  , 25.  , 28.  ,   nan,  4.  , 13.  , 34.  ,  5.  , 52.  ,\n",
       "       36.  ,   nan, 30.  , 49.  ,   nan, 29.  , 65.  ,   nan, 50.  ,\n",
       "         nan, 48.  , 34.  , 47.  , 48.  ,   nan, 38.  ,   nan, 56.  ,\n",
       "         nan,  0.75,   nan, 38.  , 33.  , 23.  , 22.  ,   nan, 34.  ,\n",
       "       29.  , 22.  ,  2.  ,  9.  ,   nan, 50.  , 63.  , 25.  ,   nan,\n",
       "       35.  , 58.  , 30.  ,  9.  ,   nan, 21.  , 55.  , 71.  , 21.  ,\n",
       "         nan, 54.  ,   nan, 25.  , 24.  , 17.  , 21.  ,   nan, 37.  ,\n",
       "       16.  , 18.  , 33.  ,   nan, 28.  , 26.  , 29.  ,   nan, 36.  ,\n",
       "       54.  , 24.  , 47.  , 34.  ,   nan, 36.  , 32.  , 30.  , 22.  ,\n",
       "         nan, 44.  ,   nan, 40.5 , 50.  ,   nan, 39.  , 23.  ,  2.  ,\n",
       "         nan, 17.  ,   nan, 30.  ,  7.  , 45.  , 30.  ,   nan, 22.  ,\n",
       "       36.  ,  9.  , 11.  , 32.  , 50.  , 64.  , 19.  ,   nan, 33.  ,\n",
       "        8.  , 17.  , 27.  ,   nan, 22.  , 22.  , 62.  , 48.  ,   nan,\n",
       "       39.  , 36.  ,   nan, 40.  , 28.  ,   nan,   nan, 24.  , 19.  ,\n",
       "       29.  ,   nan, 32.  , 62.  , 53.  , 36.  ,   nan, 16.  , 19.  ,\n",
       "       34.  , 39.  ,   nan, 32.  , 25.  , 39.  , 54.  , 36.  ,   nan,\n",
       "       18.  , 47.  , 60.  , 22.  ,   nan, 35.  , 52.  , 47.  ,   nan,\n",
       "       37.  , 36.  ,   nan, 49.  ,   nan, 49.  , 24.  ,   nan,   nan,\n",
       "       44.  , 35.  , 36.  , 30.  , 27.  , 22.  , 40.  , 39.  ,   nan,\n",
       "         nan,   nan, 35.  , 24.  , 34.  , 26.  ,  4.  , 26.  , 27.  ,\n",
       "       42.  , 20.  , 21.  , 21.  , 61.  , 57.  , 21.  , 26.  ,   nan,\n",
       "       80.  , 51.  , 32.  ,   nan,  9.  , 28.  , 32.  , 31.  , 41.  ,\n",
       "         nan, 20.  , 24.  ,  2.  ,   nan,  0.75, 48.  , 19.  , 56.  ,\n",
       "         nan, 23.  ,   nan, 18.  , 21.  ,   nan, 18.  , 24.  ,   nan,\n",
       "       32.  , 23.  , 58.  , 50.  , 40.  , 47.  , 36.  , 20.  , 32.  ,\n",
       "       25.  ,   nan, 43.  ,   nan, 40.  , 31.  , 70.  , 31.  ,   nan,\n",
       "       18.  , 24.5 , 18.  , 43.  , 36.  ,   nan, 27.  , 20.  , 14.  ,\n",
       "       60.  , 25.  , 14.  , 19.  , 18.  , 15.  , 31.  ,  4.  ,   nan,\n",
       "       25.  , 60.  , 52.  , 44.  ,   nan, 49.  , 42.  , 18.  , 35.  ,\n",
       "       18.  , 25.  , 26.  , 39.  , 45.  , 42.  , 22.  ,   nan, 24.  ,\n",
       "         nan, 48.  , 29.  , 52.  , 19.  , 38.  , 27.  ,   nan, 33.  ,\n",
       "        6.  , 17.  , 34.  , 50.  , 27.  , 20.  , 30.  ,   nan, 25.  ,\n",
       "       25.  , 29.  , 11.  ,   nan, 23.  , 23.  , 28.5 , 48.  , 35.  ,\n",
       "         nan,   nan,   nan, 36.  , 21.  , 24.  , 31.  , 70.  , 16.  ,\n",
       "       30.  , 19.  , 31.  ,  4.  ,  6.  , 33.  , 23.  , 48.  ,  0.67,\n",
       "       28.  , 18.  , 34.  , 33.  ,   nan, 41.  , 20.  , 36.  , 16.  ,\n",
       "       51.  ,   nan, 30.5 ,   nan, 32.  , 24.  , 48.  , 57.  ,   nan,\n",
       "       54.  , 18.  ,   nan,  5.  ,   nan, 43.  , 13.  , 17.  , 29.  ,\n",
       "         nan, 25.  , 25.  , 18.  ,  8.  ,  1.  , 46.  ,   nan, 16.  ,\n",
       "         nan,   nan, 25.  , 39.  , 49.  , 31.  , 30.  , 30.  , 34.  ,\n",
       "       31.  , 11.  ,  0.42, 27.  , 31.  , 39.  , 18.  , 39.  , 33.  ,\n",
       "       26.  , 39.  , 35.  ,  6.  , 30.5 ,   nan, 23.  , 31.  , 43.  ,\n",
       "       10.  , 52.  , 27.  , 38.  , 27.  ,  2.  ,   nan,   nan,  1.  ,\n",
       "         nan, 62.  , 15.  ,  0.83,   nan, 23.  , 18.  , 39.  , 21.  ,\n",
       "         nan, 32.  ,   nan, 20.  , 16.  , 30.  , 34.5 , 17.  , 42.  ,\n",
       "         nan, 35.  , 28.  ,   nan,  4.  , 74.  ,  9.  , 16.  , 44.  ,\n",
       "       18.  , 45.  , 51.  , 24.  ,   nan, 41.  , 21.  , 48.  ,   nan,\n",
       "       24.  , 42.  , 27.  , 31.  ,   nan,  4.  , 26.  , 47.  , 33.  ,\n",
       "       47.  , 28.  , 15.  , 20.  , 19.  ,   nan, 56.  , 25.  , 33.  ,\n",
       "       22.  , 28.  , 25.  , 39.  , 27.  , 19.  ,   nan, 26.  , 32.  ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].values[:]\n",
    "# => this will return a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# info of the dataframe using .info()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                     Name   Sex   \n",
       "count    891.000000  891.000000  891.000000                      891   891  \\\n",
       "unique          NaN         NaN         NaN                      891     2   \n",
       "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
       "freq            NaN         NaN         NaN                        1   577   \n",
       "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch  Ticket        Fare    Cabin   \n",
       "count   714.000000  891.000000  891.000000     891  891.000000      204  \\\n",
       "unique         NaN         NaN         NaN     681         NaN      147   \n",
       "top            NaN         NaN         NaN  347082         NaN  B96 B98   \n",
       "freq           NaN         NaN         NaN       7         NaN        4   \n",
       "mean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
       "std      14.526497    1.102743    0.806057     NaN   49.693429      NaN   \n",
       "min       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
       "25%      20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n",
       "50%      28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n",
       "75%      38.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
       "max      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe of the dataframe using .describe() (with the include='all' include the non-numeric columns)\n",
    "df.describe(include='all')\n",
    "# .describe() = numeric values / .info() = all values overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  you can access the datfarme's colums and indexes with .columns and .index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std = Standard variation represents the average distance between each data point and the mean of the dat a. It is a key metric used in \n",
    "# statistical analysis to understand the distribution of data and to identify outliers. 25% = Q1 and 50% = Q2 and 75% = Q3 \n",
    "# => quartile seperates the data into quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting with loc or iloc : df['row',['column1','column2']]\n",
    "\n",
    "#slicing :\n",
    "# :: step over \n",
    "# :-1 reverse order \n",
    "# \" : \"  => all rows or columns\n",
    "\n",
    "# select : df[ df['Age']>70 ] => select all rows where the age is greater than 70\n",
    "# just put inside the brackets the condition you want to apply"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any duplicated rows\n",
    "df.duplicated().sum() \n",
    "# to remove the duplicated rows : df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is there any missing values ? :\n",
    "# df.isnull().any()\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "# df.dropna(axis=0,inplace=True) => comes with data loss\n",
    "# drop any ro< that contains nan value in embarked column\n",
    "# df.dropna(subset=['Embarked'],inplace=True)\n",
    "# deleting data is the last option \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the null rows in embarked column\n",
    "df[df['Embarked'].isnull()]\n",
    "\n",
    "# show the most common value in embarked column\n",
    "a = df['Embarked'].mode()\n",
    "\n",
    "# fill the missing values with the mode of the Embarked column\n",
    "df['Embarked'].fillna(a[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values in the Age column with the mean of the Age column\n",
    "\n",
    "df['Age'].isnull().sum()\n",
    "a = int(df['Age'].mean())\n",
    "df['Age'].fillna(a,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any missing values left\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values in the Cabin column with diffrent cabin numbers that are not in the dataset and then replace the letter with a number in order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values in the Cabin column with 'No cabin'\n",
    "df['Cabin'].fillna('No cabin',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        891 non-null    object \n",
      " 11  Embarked     891 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#info of the dataframe using .info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      2\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "886    1\n",
       "887    1\n",
       "888    1\n",
       "889    2\n",
       "890    3\n",
       "Name: Embarked, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the type of the Embarked column to int to allow the model to work on integers\n",
    "\n",
    "df['Embarked'].unique()\n",
    "embarked_replacement = {'S':1,'C':2,'Q':3}\n",
    "df['Embarked'].replace(embarked_replacement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      2\n",
       "2      2\n",
       "3      2\n",
       "4      1\n",
       "      ..\n",
       "886    1\n",
       "887    2\n",
       "888    2\n",
       "889    1\n",
       "890    1\n",
       "Name: Sex, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change Sex column to int\n",
    "\n",
    "Sex_replacement = {'male': 1, 'female': 2}\n",
    "df['Sex'].replace(Sex_replacement,inplace=True)\n",
    "df['Sex']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_transform => transforl data to numbers and train the model to be able to predict the numbers\n",
    "# encoding diffrent values in the Cabin column to numbers and stores them in the object 'encoder'\n",
    "le = LabelEncoder()\n",
    "df['Cabin'] = le.fit_transform(df['Cabin'])\n",
    "len(df['Cabin'].unique())\n",
    "# use len() to get the size instead of visually identifying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mr or mrs or miss or master or pilot or doctor from the name column and store it in a new column called title\n",
    "df['Title'] = df['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\n",
    "df['Title'].unique()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
